{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import pickle\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Functions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_df_info(dataframe):\n",
    "    print(f\"Shape is: {dataframe.shape}\")\n",
    "    display(dataframe.head())\n",
    "\n",
    "\n",
    "def get_filtered_data(path_csv_file, element_type, new_value_name):\n",
    "    data = pd.read_csv(path_csv_file)\n",
    "    data = data[(data['country_code'].isna() == False) & (data['country_code'] != 'OWID_WRL')]\n",
    "    data.rename(columns={'year': 'date'}, inplace=True)\n",
    "    data['date'] = pd.to_datetime(data['date'], errors='coerce')\n",
    "    data['year'] = data['date'].dt.year\n",
    "    data.drop('date', axis=1, inplace=True)\n",
    "\n",
    "    data = data[data['element'] == element_type]\n",
    "    data.rename(columns={'value': new_value_name}, inplace=True)\n",
    "    \n",
    "    return data[['country_code', 'year', new_value_name]]\n",
    "\n",
    "\n",
    "def fill_na_with_mean(dataframe, column_name):\n",
    "    mean = dataframe[column_name].mean()\n",
    "    dataframe[column_name] = dataframe[column_name].fillna(mean)\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def display_heatmap(dataframe):\n",
    "    corr=dataframe.corr()\n",
    "\n",
    "    mask=np.triu(np.ones_like(corr, dtype=bool))     # generate a mask for the upper triangle\n",
    "\n",
    "    f, ax=plt.subplots(figsize=(11, 9))                 # set up the matplotlib figure\n",
    "\n",
    "    cmap=sns.diverging_palette(220, 10, as_cmap=True)   # generate a custom diverging colormap\n",
    "\n",
    "    sns.heatmap(corr, mask=mask, cmap=cmap,             # draw the heatmap with the mask and correct aspect ratio\n",
    "                vmax=.3, center=0, square=True,\n",
    "                linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(models, dataframe, label):\n",
    "    \n",
    "    fitted_models_list = []\n",
    "    min_max_scaler_list = []\n",
    "\n",
    "    r2_list = []\n",
    "    mse_list = []\n",
    "    rmse_list = []\n",
    "    mae_list = []\n",
    "\n",
    "    for model in models:\n",
    "\n",
    "        print(f\"====== {model} ======\")\n",
    "\n",
    "        dataframe = dataframe.sample(frac=1)\n",
    "\n",
    "        y = dataframe[label]\n",
    "        X = dataframe.drop(label, axis=1)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "        # Scaling data = X_train\n",
    "        min_max_scaler = MinMaxScaler().fit(X_train)\n",
    "        X_train_normalized = min_max_scaler.transform(X_train)\n",
    "        X_train_normalized = pd.DataFrame(X_train_normalized)\n",
    "\n",
    "        # Scaling data = X_test\n",
    "        X_test_normalized = min_max_scaler.transform(X_test)\n",
    "        X_test_normalized = pd.DataFrame(X_test_normalized)\n",
    "\n",
    "        model.fit(X_train_normalized, y_train)\n",
    "\n",
    "        # Make predictions on the test data\n",
    "        y_pred = model.predict(X_test_normalized)\n",
    "\n",
    "        # R2 validation\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        print(\"R2:\", r2)\n",
    "\n",
    "        # MSE validation\n",
    "        mse=mean_squared_error(y_test, y_pred)\n",
    "        print(\"MSE:\", mse)\n",
    "\n",
    "        # RMSE validation\n",
    "        rmse = np.sqrt(mse)\n",
    "        print(\"RMSE:\", rmse)\n",
    "\n",
    "        # MAE validation\n",
    "        mae=mean_absolute_error(y_test, y_pred)\n",
    "        print(\"MAE:\", mae)\n",
    "\n",
    "        fitted_models_list.append({\n",
    "            'model': model,\n",
    "            'min_max_scaler' : min_max_scaler\n",
    "        })\n",
    "        min_max_scaler_list.append(min_max_scaler)\n",
    "\n",
    "        r2_list.append(r2)\n",
    "        mse_list.append(mse)\n",
    "        rmse_list.append(rmse)\n",
    "        mae_list.append(mae)\n",
    "\n",
    "\n",
    "    summary = {\n",
    "        'Algorithm': [item['model'] for item in fitted_models_list],\n",
    "        'R2': r2_list,\n",
    "        'MSE': mse_list,\n",
    "        'RMSE': rmse_list,\n",
    "        'MAE': mae_list\n",
    "    }\n",
    "    summary = pd.DataFrame(summary)\n",
    "\n",
    "    return {\n",
    "        'summary' : summary,\n",
    "        'models' : fitted_models_list\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_ordered_rmse(dataframe_summary):\n",
    "    clear_output()\n",
    "    display(dataframe_summary.sort_values(by='RMSE'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `UN_paper_pulp_import_export.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'wood-pulp-business/data/cleaned/UN_paper_pulp_import_export.csv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Productions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_pulp_production_data = get_filtered_data(file, 'Production', 'paper_pulp_prod_tonnes')\n",
    "paper_pulp_production_data.to_csv('data/paper_pulp_production_data.csv', index=False)\n",
    "display_df_info(paper_pulp_production_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Exports`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_pulp_export_data = get_filtered_data(file, 'Export Quantity', 'paper_pulp_export_tonnes')\n",
    "paper_pulp_export_data.to_csv('data/paper_pulp_export_data.csv', index=False)\n",
    "display_df_info(paper_pulp_export_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Imports`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_pulp_import_data = get_filtered_data(file, 'Import Quantity', 'paper_pulp_import_tonnes')\n",
    "paper_pulp_import_data.to_csv('data/paper_pulp_import_data.csv', index=False)\n",
    "display_df_info(paper_pulp_import_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `UN_wood_pulp_import_export.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'wood-pulp-business/data/cleaned/UN_wood_pulp_import_export.csv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Productions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wood_pulp_production_data = get_filtered_data(file, 'Production', 'wood_pulp_production_tonnes')\n",
    "wood_pulp_production_data.to_csv('data/wood_pulp_production_data.csv', index=False)\n",
    "display_df_info(wood_pulp_production_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Exports`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wood_pulp_export_data = get_filtered_data(file, 'Export Quantity', 'wood_pulp_export_tonnes')\n",
    "wood_pulp_export_data.to_csv('data/wood_pulp_export_data.csv', index=False)\n",
    "display_df_info(wood_pulp_export_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Imports`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wood_pulp_import_data = get_filtered_data(file, 'Import Quantity', 'wood_pulp_import_tonnes')\n",
    "wood_pulp_import_data.to_csv('data/wood_pulp_import_data.csv', index=False)\n",
    "display_df_info(wood_pulp_import_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Concat Dataframes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(paper_pulp_production_data, paper_pulp_export_data, on=['country_code', 'year'], how='outer')\n",
    "data = pd.merge(data, paper_pulp_import_data, on=['country_code', 'year'], how='outer')\n",
    "\n",
    "data = pd.merge(data, wood_pulp_production_data, on=['country_code', 'year'], how='outer')\n",
    "data = pd.merge(data, wood_pulp_export_data, on=['country_code', 'year'], how='outer')\n",
    "data = pd.merge(data, wood_pulp_import_data, on=['country_code', 'year'], how='outer')\n",
    "\n",
    "display_df_info(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Concat Paper Prices from producer_paper_price_evolution.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_price_data = pd.read_csv('wood-pulp-business/data/cleaned/producer_paper_price_evolution.csv')\n",
    "\n",
    "paper_price_data.columns = ['date', 'paper_price']\n",
    "paper_price_data['date'] = pd.to_datetime(paper_price_data['date'], errors='coerce')\n",
    "paper_price_data['year'] = paper_price_data['date'].dt.year\n",
    "paper_price_data.drop('date', axis=1, inplace=True)\n",
    "\n",
    "display_df_info(paper_price_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_price_data = paper_price_data.groupby('year')['paper_price'].mean().reset_index()\n",
    "display_df_info(paper_price_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(data, paper_price_data, on=['year'], how='outer')\n",
    "display_df_info(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Concat Wood Pulp Prices from producer_wood_pulp_price_evolution.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wood_pulp_price_data = pd.read_csv('wood-pulp-business/data/cleaned/producer_wood_pulp_price_evolution.csv')\n",
    "\n",
    "wood_pulp_price_data.columns = ['date', 'wood_pulp_price']\n",
    "wood_pulp_price_data['date'] = pd.to_datetime(wood_pulp_price_data['date'], errors='coerce')\n",
    "wood_pulp_price_data['year'] = wood_pulp_price_data['date'].dt.year\n",
    "wood_pulp_price_data.drop('date', axis=1, inplace=True)\n",
    "\n",
    "display_df_info(wood_pulp_price_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wood_pulp_price_data = wood_pulp_price_data.groupby('year')['wood_pulp_price'].mean().reset_index()\n",
    "display_df_info(wood_pulp_price_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(data, wood_pulp_price_data, on=['year'], how='outer')\n",
    "display_df_info(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Work on the model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('data/data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['paper_pulp_prod_tonnes', 'paper_pulp_export_tonnes', 'paper_pulp_import_tonnes', 'wood_pulp_production_tonnes', 'wood_pulp_export_tonnes', 'wood_pulp_import_tonnes', 'paper_price']\n",
    "\n",
    "for col in cols:\n",
    "    data = fill_na_with_mean(data, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('country_code', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_df_info(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('data/data_cleaned.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Check correlations`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_heatmap(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Test algorithms`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_test = [\n",
    "    LinearRegression(n_jobs=-1),\n",
    "    Lasso(),\n",
    "    Ridge(),\n",
    "    ElasticNet(),\n",
    "    XGBRegressor(),\n",
    "    LGBMRegressor(n_jobs=-1),\n",
    "    DecisionTreeRegressor(),\n",
    "    KNeighborsRegressor(n_jobs=-1),\n",
    "    MLPRegressor(),\n",
    "    RandomForestRegressor(n_jobs=-1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_paper_price = compare_models(models=models_to_test, dataframe=data.drop('wood_pulp_price', axis=1), label='paper_price')\n",
    "display_ordered_rmse(results_paper_price['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LinearRegression(n_jobs=-1) seems the best\n",
    "\n",
    "paper_price_model_with_scaler = results_paper_price['models'][0]\n",
    "\n",
    "with open(f'data/models/paper_price_model_with_scaler.pkl', 'wb') as file:\n",
    "    pickle.dump(paper_price_model_with_scaler, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_wood_pulp_price = compare_models(models=models_to_test, dataframe=data.drop('paper_price', axis=1), label='wood_pulp_price')\n",
    "display_ordered_rmse(results_wood_pulp_price['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNeighborsRegressor(n_jobs=-1) seems the best\n",
    "\n",
    "wood_pulp_price_model_with_scaler = results_wood_pulp_price['models'][-3]\n",
    "\n",
    "with open(f'data/models/wood_pulp_price_model_with_scaler.pkl', 'wb') as file:\n",
    "    pickle.dump(wood_pulp_price_model_with_scaler, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
